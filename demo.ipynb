{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4002,"status":"ok","timestamp":1682055270959,"user":{"displayName":"A K","userId":"05758281892400312766"},"user_tz":-330},"id":"zS_aGsFIFkt3","outputId":"49093836-c03e-4fd4-85c8-6b397103f380"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: opencv-python in /usr/local/lib/python3.9/dist-packages (4.7.0.72)\n","Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.9/dist-packages (from opencv-python) (1.22.4)\n"]}],"source":["!pip install opencv-python"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BTix7-cPHL-7"},"outputs":[],"source":["import cv2 as cv"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yYzSfdpRFsfr"},"outputs":[],"source":["import matplotlib.pyplot as plt"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-k7lyL_3G20v"},"outputs":[],"source":["net=cv.dnn.readNetFromTensorflow(\"/content/drive/MyDrive/graph_opt.pb\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NkqYzMr1Hp90"},"outputs":[],"source":["inWidth=368\n","inHeight=368\n","thr=0.2"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tQrUPOwqH7Zi"},"outputs":[],"source":["BODY_PARTS = { \"Nose\": 0, \"Neck\": 1, \"RShoulder\": 2, \"RElbow\": 3, \"RWrist\": 4,\n","               \"LShoulder\": 5, \"LElbow\": 6, \"LWrist\": 7, \"RHip\": 8, \"RKnee\": 9,\n","               \"RAnkle\": 10, \"LHip\": 11, \"LKnee\": 12, \"LAnkle\": 13, \"REye\": 14,\n","               \"LEye\": 15, \"REar\": 16, \"LEar\": 17, \"Background\": 18 }\n","\n","POSE_PAIRS = [ [\"Neck\", \"RShoulder\"], [\"Neck\", \"LShoulder\"], [\"RShoulder\", \"RElbow\"],\n","               [\"RElbow\", \"RWrist\"], [\"LShoulder\", \"LElbow\"], [\"LElbow\", \"LWrist\"],\n","               [\"Neck\", \"RHip\"], [\"RHip\", \"RKnee\"], [\"RKnee\", \"RAnkle\"], [\"Neck\", \"LHip\"],\n","               [\"LHip\", \"LKnee\"], [\"LKnee\", \"LAnkle\"], [\"Neck\", \"Nose\"], [\"Nose\", \"REye\"],\n","               [\"REye\", \"REar\"], [\"Nose\", \"LEye\"], [\"LEye\", \"LEar\"] ]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AuDudLY4JQ5v"},"outputs":[],"source":["cap= cv.VideoCapture(\"/content/drive/MyDrive/280223_norobot.mp4\")\n","cap.set(3,800)\n","cap.set(4,800)\n","if not cap.isOpened():\n","  cap= cv.VideoCapture(0)\n","if not cap.isOpened():\n","  raiseIOError(\"cannot open\")\n","while cv.waitKey(1)<0:\n","  hasFrame,frame  =cap.read()\n","  if not hasFrame:\n","    cv.waitKey()\n","    break\n","    frameWidth=frame.shape[1]\n","    frameHeightframe.shape[0]\n","    net.setInput(cv.dnn.blobFromImage(frame,1.0,(inWidth,inHeight),(127.5,127.5,127.5),swapRB=True, crop=False))\n","    out=net.forward()\n","    out=out[:,:19,:,:]\n","    assert(len(BODY_PARTS) == out.shape[1])\n","\n","    points = []\n","    for i in range(len(BODY_PARTS)):\n","        # Slice heatmap of corresponging body's part.\n","        heatMap = out[0, i, :, :]\n","\n","        # Originally, we try to find all the local maximums. To simplify a sample\n","        # we just find a global one. However only a single pose at the same time\n","        # could be detected this way.\n","        _, conf, _, point = cv.minMaxLoc(heatMap)\n","        x = (frameWidth * point[0]) / out.shape[3]\n","        y = (frameHeight * point[1]) / out.shape[2]\n","        # Add a point if it's confidence is higher than threshold.\n","        points.append((int(x), int(y)) if conf >thr else None)\n","\n","    for pair in POSE_PAIRS:\n","        partFrom = pair[0]\n","        partTo = pair[1]\n","        assert(partFrom in BODY_PARTS)\n","        assert(partTo in BODY_PARTS)\n","\n","        idFrom = BODY_PARTS[partFrom]\n","        idTo = BODY_PARTS[partTo]\n","\n","        if points[idFrom] and points[idTo]:\n","            cv.line(frame, points[idFrom], points[idTo], (0, 255, 0), 3)\n","            cv.ellipse(frame, points[idFrom], (3, 3), 0, 0, 360, (0, 0, 255), cv.FILLED)\n","            cv.ellipse(frame, points[idTo], (3, 3), 0, 0, 360, (0, 0, 255), cv.FILLED)\n","\n","    t, _ = net.getPerfProfile()\n","    freq = cv.getTickFrequency() / 1000\n","    cv.putText(frame, '%.2fms' % (t / freq), (10, 20), cv.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0))\n","\n","    # cv.imshow('OpenPose using OpenCV', frame)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iyf8wAMAI-aZ"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[],"mount_file_id":"1YYiQf5wumkeDNFmg_qwbJDpEmyain5TU","authorship_tag":"ABX9TyNdBsfmQnTDzBz0kICthyRP"},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}